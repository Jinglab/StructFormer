% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/run_pretrain_BERT.r
\name{run_Structformer_pretrainBERT}
\alias{run_Structformer_pretrainBERT}
\title{Calculate the embedding for spots/cells}
\usage{
run_Structformer_pretrainBERT(
  dat,
  gene_list,
  block_size = 260,
  vocab_size = 50000,
  hidden_size = 768,
  num_hidden_layers = 6,
  num_attention_heads = 12,
  max_position_embeddings = 512,
  mlm_probability = 0.15,
  num_train_epochs = 10000,
  per_device_train_batch_size = 16,
  save_steps = 10000,
  save_total_limit = 60000,
  save_checkpoint_path,
  envir_path
)
}
\arguments{
\item{dat}{The Seurat object or dataframe which contains sentenences.}

\item{gene_list}{The complete set of genes used to construct the sentences.}

\item{block_size}{The input sentences have a maximum word count for a single sentence.}

\item{vocab_size}{The total number of genes available.}

\item{hidden_size}{The length of the output vector in the last layer of the pre-trained model.}

\item{num_hidden_layers}{The hidden layer numbers.}

\item{num_attention_heads}{The anttention heads in model.}

\item{max_position_embeddings}{The defined maximum length of a sentence.}

\item{mlm_probability}{The probability of masked words in a sentence.}

\item{num_train_epochs}{Training epochs.}

\item{per_device_train_batch_size}{The batch size.}

\item{save_steps}{After save_steps to automately save model.}

\item{save_total_limit}{The limit on steps that can be used for saving the model. If this number is exceeded, the model will not be automatically saved when running the save_steps.}

\item{save_checkpoint_path}{The save path for the Structformer trained model.}

\item{envir_path}{The python env path.}

\item{with_gpu}{Default: FALSE. Specify TRUE or FALSE to indicate whether to use a GPU.}
}
\value{
Runing the pre-training process
}
\description{
Run the Structformer trained model or a pre-trained BERT model to extract the embeddings of the spots/cells.
}
